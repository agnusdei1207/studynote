+++
title = "ë¹…ë°ì´í„° (Big Data)"
date = 2025-03-01

[extra]
categories = "ict-bigdata"
+++

# ë¹…ë°ì´í„° (Big Data)

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3ì¤„ ìš”ì•½)
> **ëŒ€ëŸ‰ì˜ ì •í˜•/ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ê°€ì¹˜ë¥¼ ì°½ì¶œ**í•˜ëŠ” ê¸°ìˆ . Volume(ê·œëª¨), Velocity(ì†ë„), Variety(ë‹¤ì–‘ì„±)ì˜ 3V íŠ¹ì„±. ìˆ˜ì§‘â†’ì €ì¥â†’ì²˜ë¦¬â†’ë¶„ì„â†’ì‹œê°í™”ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í™œìš©.

## 1. ê°œë…
ë¹…ë°ì´í„°ëŠ” **ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ë„êµ¬ë¡œ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ìš´ ëŒ€ê·œëª¨ ë°ì´í„° ì§‘í•©**ìœ¼ë¡œ, ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ìƒì„±ë˜ëŠ” ë°©ëŒ€í•œ ì–‘ì˜ ì •í˜•/ë¹„ì •í˜• ë°ì´í„°ë¥¼ ì˜ë¯¸í•œë‹¤.

> ë¹„ìœ : "ë°ì´í„°ì˜ ë°”ë‹¤" - ì—„ì²­ë‚œ ì–‘ì˜ ë°ì´í„°ì—ì„œ ì§„ì£¼(ê°€ì¹˜)ë¥¼ ì°¾ëŠ” ê²ƒ

## 2. ë¹…ë°ì´í„°ì˜ íŠ¹ì„± (3V â†’ 5V)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ë¹…ë°ì´í„°ì˜ íŠ¹ì„± (5V)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1. Volume (ê·œëª¨)                                       â”‚
â”‚     - í˜íƒ€ë°”ì´íŠ¸(PB), ì—‘ì‚¬ë°”ì´íŠ¸(EB) ë‹¨ìœ„               â”‚
â”‚     - ì˜ˆ: í˜ì´ìŠ¤ë¶ ì¼ì¼ ë°ì´í„° 4PB                     â”‚
â”‚                                                         â”‚
â”‚  2. Velocity (ì†ë„)                                     â”‚
â”‚     - ì‹¤ì‹œê°„/ê·¼ì‹¤ì‹œê°„ ì²˜ë¦¬                              â”‚
â”‚     - ì˜ˆ: ì£¼ì‹ ê±°ë˜, ì„¼ì„œ ë°ì´í„°                       â”‚
â”‚                                                         â”‚
â”‚  3. Variety (ë‹¤ì–‘ì„±)                                    â”‚
â”‚     - ì •í˜•: DB, ìŠ¤í”„ë ˆë“œì‹œíŠ¸                           â”‚
â”‚     - ë°˜ì •í˜•: JSON, XML, ë¡œê·¸                          â”‚
â”‚     - ë¹„ì •í˜•: ì˜ìƒ, ìŒì„±, í…ìŠ¤íŠ¸                       â”‚
â”‚                                                         â”‚
â”‚  4. Veracity (ì •í™•ì„±)                                   â”‚
â”‚     - ë°ì´í„° í’ˆì§ˆ, ì‹ ë¢°ì„±                              â”‚
â”‚     - ë…¸ì´ì¦ˆ, ê²°ì¸¡ì¹˜ ì²˜ë¦¬                              â”‚
â”‚                                                         â”‚
â”‚  5. Value (ê°€ì¹˜)                                        â”‚
â”‚     - ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ                           â”‚
â”‚     - ì˜ì‚¬ê²°ì • ì§€ì›                                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 3. ë¹…ë°ì´í„° ì²˜ë¦¬ ê¸°ìˆ 

### 3.1 í•˜ë‘¡ (Hadoop)
```
í•˜ë‘¡ ì—ì½”ì‹œìŠ¤í…œ:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hadoop Ecosystem                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚    HDFS     â”‚    â”‚ MapReduce   â”‚                  â”‚
â”‚   â”‚(ë¶„ì‚° íŒŒì¼   â”‚    â”‚(ë¶„ì‚° ì²˜ë¦¬)  â”‚                  â”‚
â”‚   â”‚   ì‹œìŠ¤í…œ)   â”‚    â”‚             â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚    YARN     â”‚    â”‚   Hive      â”‚                  â”‚
â”‚   â”‚(ìì› ê´€ë¦¬)  â”‚    â”‚(SQL ì¸í„°í˜ì´ìŠ¤)â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚    HBase    â”‚    â”‚    Pig      â”‚                  â”‚
â”‚   â”‚(NoSQL DB)   â”‚    â”‚(ìŠ¤í¬ë¦½íŠ¸)   â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HDFS (Hadoop Distributed File System):
- ë¸”ë¡ ë‹¨ìœ„ ì €ì¥ (128MB)
- ë³µì œ (ê¸°ë³¸ 3ë³¸)
- ë§ˆìŠ¤í„°-ìŠ¬ë ˆì´ë¸Œ êµ¬ì¡°

MapReduce:
- Map: ë°ì´í„° ë¶„í• , ë³€í™˜
- Reduce: ì§‘ê³„, ê²°í•©
```

### 3.2 ìŠ¤íŒŒí¬ (Spark)
```
ì¸ë©”ëª¨ë¦¬ ë¶„ì‚° ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬

íŠ¹ì§•:
- í•˜ë‘¡ë³´ë‹¤ 100ë°° ë¹ ë¦„ (ì¸ë©”ëª¨ë¦¬)
- ë°°ì¹˜ + ìŠ¤íŠ¸ë¦¬ë° í†µí•©
- ë‹¤ì–‘í•œ API (SQL, ML, Graph)

êµ¬ì¡°:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Spark Core                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Spark SQL â”‚ MLlib â”‚ GraphX â”‚ Streaming â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4. ë¹…ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìˆ˜ì§‘    â”‚â”€â”€â†’â”‚  ì €ì¥    â”‚â”€â”€â†’â”‚  ì²˜ë¦¬    â”‚â”€â”€â†’â”‚  ë¶„ì„    â”‚â”€â”€â†’â”‚  ì‹œê°í™”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ìˆ˜ì§‘:
- ë¡œê·¸, ì„¼ì„œ, SNS, IoT
- Flume, Kafka

ì €ì¥:
- HDFS, S3, NoSQL
- Data Lake

ì²˜ë¦¬:
- ì •ì œ, ë³€í™˜, í†µí•©
- ETL/ELT

ë¶„ì„:
- í†µê³„, ë§ˆì´ë‹, ML
- í†µì°° ë„ì¶œ

ì‹œê°í™”:
- ëŒ€ì‹œë³´ë“œ, ë¦¬í¬íŠ¸
- Tableau, Power BI
```

## 5. ì½”ë“œ ì˜ˆì‹œ

```python
from dataclasses import dataclass
from typing import List, Dict, Any
from collections import Counter
import json

@dataclass
class DataPoint:
    """ë°ì´í„° í¬ì¸íŠ¸"""
    timestamp: str
    source: str
    data: Dict[str, Any]

class DataCollector:
    """ë°ì´í„° ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜"""

    def __init__(self):
        self.collected_data: List[DataPoint] = []

    def collect(self, source: str, data: Dict) -> int:
        """ë°ì´í„° ìˆ˜ì§‘"""
        import datetime
        point = DataPoint(
            timestamp=datetime.datetime.now().isoformat(),
            source=source,
            data=data
        )
        self.collected_data.append(point)
        return len(self.collected_data)

class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬"""

    def __init__(self):
        self.processed_data = []

    def clean(self, data: List[DataPoint]) -> List[DataPoint]:
        """ë°ì´í„° ì •ì œ"""
        cleaned = []
        for point in data:
            # ê²°ì¸¡ì¹˜ ì œê±°
            if point.data is not None:
                cleaned.append(point)
        return cleaned

    def transform(self, data: List[DataPoint]) -> List[Dict]:
        """ë°ì´í„° ë³€í™˜"""
        transformed = []
        for point in data:
            item = {
                'timestamp': point.timestamp,
                'source': point.source,
                **point.data
            }
            transformed.append(item)
        return transformed

class MapReduceSimulator:
    """MapReduce ì‹œë®¬ë ˆì´ì…˜"""

    @staticmethod
    def map_phase(data: List[Dict], key_field: str) -> Dict[str, List]:
        """Map ë‹¨ê³„: í‚¤ë³„ ê·¸ë£¹í™”"""
        mapped = {}
        for item in data:
            key = item.get(key_field, 'unknown')
            if key not in mapped:
                mapped[key] = []
            mapped[key].append(item)
        return mapped

    @staticmethod
    def reduce_phase(mapped: Dict[str, List],
                     reduce_func) -> Dict[str, Any]:
        """Reduce ë‹¨ê³„: ì§‘ê³„"""
        reduced = {}
        for key, values in mapped.items():
            reduced[key] = reduce_func(values)
        return reduced

# ì‚¬ìš© ì˜ˆì‹œ
print("=== ë¹…ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ===\n")

# ìˆ˜ì§‘
collector = DataCollector()
collector.collect("web_log", {"page": "/home", "user_id": "user1", "duration": 30})
collector.collect("web_log", {"page": "/product", "user_id": "user2", "duration": 45})
collector.collect("web_log", {"page": "/home", "user_id": "user3", "duration": 20})
collector.collect("sensor", {"device": "temp_01", "value": 25.5})
collector.collect("sensor", {"device": "temp_01", "value": 26.0})

print(f"ìˆ˜ì§‘ëœ ë°ì´í„°: {len(collector.collected_data)}ê±´")

# ì²˜ë¦¬
processor = DataProcessor()
cleaned = processor.clean(collector.collected_data)
transformed = processor.transform(cleaned)

# MapReduce: í˜ì´ì§€ë³„ ë°©ë¬¸ íšŸìˆ˜
web_data = [t for t in transformed if t['source'] == 'web_log']
mapped = MapReduceSimulator.map_phase(web_data, 'page')
page_counts = MapReduceSimulator.reduce_phase(
    mapped,
    lambda values: len(values)
)

print("\ní˜ì´ì§€ë³„ ë°©ë¬¸ íšŸìˆ˜:")
for page, count in page_counts.items():
    print(f"  {page}: {count}íšŒ")

# ì„¼ì„œ ë°ì´í„° í‰ê· 
sensor_data = [t for t in transformed if t['source'] == 'sensor']
mapped = MapReduceSimulator.map_phase(sensor_data, 'device')
avg_values = MapReduceSimulator.reduce_phase(
    mapped,
    lambda values: sum(v['value'] for v in values) / len(values)
)

print("\nì„¼ì„œë³„ í‰ê· ê°’:")
for device, avg in avg_values.items():
    print(f"  {device}: {avg:.2f}")
```

## 6. ë¹…ë°ì´í„° í™œìš© ë¶„ì•¼

```
1. ë¹„ì¦ˆë‹ˆìŠ¤
   - ê³ ê° í–‰ë™ ë¶„ì„
   - ìˆ˜ìš” ì˜ˆì¸¡
   - ë§ˆì¼€íŒ… ìµœì í™”

2. ê³µê³µ
   - ìŠ¤ë§ˆíŠ¸ì‹œí‹°
   - êµí†µ ë¶„ì„
   - ì¬ë‚œ ì˜ˆì¸¡

3. ì˜ë£Œ
   - ì§ˆë³‘ ì˜ˆì¸¡
   - ì‹ ì•½ ê°œë°œ
   - ì§„ë‹¨ ë³´ì¡°

4. ê¸ˆìœµ
   - ì‚¬ê¸° íƒì§€
   - ì‹ ìš© í‰ê°€
   - ì•Œê³ ë¦¬ì¦˜ íŠ¸ë ˆì´ë”©
```

## 7. ì¥ë‹¨ì 

### ì¥ì 
| ì¥ì  | ì„¤ëª… |
|-----|------|
| í†µì°°ë ¥ | ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬ |
| ì˜ì‚¬ê²°ì • | ë°ì´í„° ê¸°ë°˜ íŒë‹¨ |
| íš¨ìœ¨ì„± | í”„ë¡œì„¸ìŠ¤ ìµœì í™” |
| í˜ì‹  | ìƒˆë¡œìš´ ë¹„ì¦ˆë‹ˆìŠ¤ |

### ë‹¨ì 
| ë‹¨ì  | ì„¤ëª… |
|-----|------|
| ë¹„ìš© | ì¸í”„ë¼, ì¸ë ¥ |
| ë³µì¡ì„± | ê¸°ìˆ ì  ë‚œì´ë„ |
| í”„ë¼ì´ë²„ì‹œ | ê°œì¸ì •ë³´ ì´ìŠˆ |
| í’ˆì§ˆ | ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ |

## 8. ì‹¤ë¬´ì—ì„ ? (ê¸°ìˆ ì‚¬ì  íŒë‹¨)
- **í”Œë«í¼**: AWS EMR, GCP BigQuery, Azure Synapse
- **ì‹¤ì‹œê°„**: Kafka + Spark Streaming
- **Data Lake**: S3 + Glue + Athena
- **ML íŒŒì´í”„ë¼ì¸**: MLflow, Kubeflow

## 9. ê´€ë ¨ ê°œë…
- ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤
- ë°ì´í„° ë§ˆì´ë‹
- ë¨¸ì‹ ëŸ¬ë‹
- í•˜ë‘¡

---

## ì–´ë¦°ì´ë¥¼ ìœ„í•œ ì¢…í•© ì„¤ëª…

**ë¹…ë°ì´í„°ëŠ” "ì—„ì²­ í° ì •ë³´ ì°½ê³ "ì˜ˆìš”!**

### ì–¼ë§ˆë‚˜ í´ê¹Œìš”? ğŸ“Š
```
ì¼ë°˜ ë°ì´í„°:
"ì±…ìƒ ì„œë ì •ë„"

ë¹…ë°ì´í„°:
"ë„ì„œê´€ ì „ì²´!"
- í˜ì´ìŠ¤ë¶ í•˜ë£¨ì— 4PB
  (ì‚¬ì§„ 4000ì–µ ì¥)
```

### 3ê°€ì§€ íŠ¹ì„± ğŸ”¢
```
Volume: ì—„ì²­ ë§ì•„ìš”!
Velocity: ë¹¨ë¦¬ ë“¤ì–´ì™€ìš”!
Variety: ì—¬ëŸ¬ ê°€ì§€ í˜•íƒœì˜ˆìš”!
  - ê¸€, ì‚¬ì§„, ì˜ìƒ, ì†Œë¦¬
```

### ë¬´ì—‡ì„ í• ê¹Œìš”? ğŸ¯
```
ìœ íŠœë¸Œ:
"ì–´ë–¤ ì˜ìƒì„ ì¢‹ì•„í• ê¹Œ?"

ë„·í”Œë¦­ìŠ¤:
"ë‹¤ìŒì—” ë­˜ ë³¼ê¹Œ?"

ì•„ë§ˆì¡´:
"ì´ê±°ë„ ì‚´ë˜?"
```

**ë¹„ë°€**: ë‚´ê°€ ë³¸ ê²ƒ, í´ë¦­í•œ ê²ƒ ë‹¤ ê¸°ë¡ë¼ìš”! ğŸ“±âœ¨
