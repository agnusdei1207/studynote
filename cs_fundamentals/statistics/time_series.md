# 시계열 (Time Series)

## 1. 개념

시계열(Time Series)은 시간 순서에 따라 관측된 데이터의 집합으로, 일정한 시간 간격 또는 불규칙한 시점에서 수집된 연속적인 데이터를 의미합니다. 시간적 의존성(Temporal Dependence)을 가진 데이터의 패턴을 분석하고 미래를 예측하는 통계적 기법을 말합니다.

## 2. 등장 배경

| 구분 | 내용 |
|------|------|
| **경제 및 금융** | 주가, 환율, 이자율 등 시계열 데이터 예측 필요 (19세기 말~20세기 초) |
| **기상 및 농업** | 기온, 강수량, 작물 수확량 등 계절적 패턴 분석 필요 |
| **통신 및 네트워크** | 트래픽, 패킷 전송량, 서비스 사용량 모니터링 및 예측 |
| **빅데이터 시대 (Big Data Era)** | IoT 센서 데이터, 소셜 미디어, 웹 로그 등 대규모 시계열 데이터 생성 |
| **비즈니스 인텔리전스 (Business Intelligence, BI)** | 판매 예측, 재고 관리, 수요 예측 등 의사결정 지원 |

## 3. 구성 요소

### 3.1 시계열의 4가지 구성 요소

| 구성 요소 | 설명 | 주기성 | 예시 |
|-----------|------|--------|------|
| **추세 (Trend)** | 장기적인 데이터의 증가 또는 감소 패턴 | 없음 | 기업 성장, 인구 증가, 기술 발전 |
| **계절성 (Seasonality)** | 고정된 주기(일, 월, 분기, 연도)로 반복되는 패턴 | 있음 | 명절 판매량, 여름철 에어컨 판매 |
| **순환성 (Cyclicity)** | 고정된 주기가 없는 장기적 반복 패턴 | 없음 | 경기 순환, 스포츠 인기 변화 |
| **불규칙성 (Irregularity, Noise)** | 예측 불가능한 무작위 변동 | 없음 | 자연재해,突发事件, 잡음 |

### 3.2 시계열 데이터의 특성

| 특성 | 설명 | 기술적 의미 |
|------|------|-----------|
| **정상성 (Stationarity)** | 평균, 분산, 자기공분산이 시간에 따라 일정함 | 통계적 분석의 전제 조건 |
| **비정상성 (Non-stationarity)** | 평균, 분산이 시간에 따라 변함 | 차분(Differencing) 등으로 변환 필요 |
| **시간적 의존성 (Temporal Dependence)** | 과거의 값이 현재/미래의 값에 영향 | 자기상관(Autocorrelation) 분석 |
| **시간적 불변성 (Temporal Invariance)** | 데이터 패턴이 시간 이동에 따라 유사 | 모델의 일반화 능력 |

## 4. 핵심 원리

### 4.1 ARIMA 모델 (Autoregressive Integrated Moving Average)

ARIMA 모델은 시계열 분석의 가장 대표적인 방법으로, 세 가지 구성 요소로 결합됩니다.

$$
\text{ARIMA}(p, d, q) = \text{AR}(p) + I(d) + \text{MA}(q)
$$

#### 4.1.1 AR (Autoregressive, 자기회귀)

과거의 값들이 현재 값에 선형적으로 영향을 미치는 모델

$$
Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \cdots + \phi_p Y_{t-p} + \epsilon_t
$$

- $Y_t$: 시점 $t$에서의 값
- $\phi$: 자기회귀 계수
- $p$: 자기회귀 차수
- $\epsilon_t$: 백색 잡음(White Noise)

**특징**: PACF(Partial Autocorrelation Function)를 통해 $p$ 결정

#### 4.1.2 MA (Moving Average, 이동평균)

과거의 예측 오차들이 현재 값에 영향을 미치는 모델

$$
Y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}
$$

- $\mu$: 시계열의 평균
- $\theta$: 이동평균 계수
- $q$: 이동평균 차수

**특징**: ACF(Autocorrelation Function)를 통해 $q$ 결정

#### 4.1.3 I (Integrated, 차분)

비정상 시계열을 정상 시계열로 변환하는 과정

$$
\Delta Y_t = Y_t - Y_{t-1}
$$

- $d$: 차분 차수

**특징**: 정상성 검정(ADF Test, KPSS Test)을 통해 $d$ 결정

### 4.2 SARIMA 모델 (Seasonal ARIMA)

계절성이 있는 시계열 데이터를 위한 확장 모델

$$
\text{SARIMA}(p, d, q)(P, D, Q)_s
$$

| 파라미터 | 설명 | 결정 방법 |
|---------|------|-----------|
| $(P, D, Q)$ | 계절성 ARIMA 차수 | 계절성 주기 $s$ 기반 분석 |
| $s$ | 계절성 주기 | ACF/ACF의 계절적 피크 확인 |

### 4.3 지수평활법 (Exponential Smoothing)

최근 데이터에 더 큰 가중치를 부여하는 예측 방법

#### 4.3.1 단순 지수평활법 (Simple Exponential Smoothing, SES)

$$
\hat{Y}_{t+1} = \alpha Y_t + (1-\alpha)\hat{Y}_t
$$

- $\alpha$: 평활 계수 ($0 < \alpha < 1$)
- 추세나 계절성이 없는 데이터에 적합

#### 4.3.2 이중 지수평활법 (Double Exponential Smoothing, Holt's Method)

$$
\begin{align}
\text{수준: } L_t &= \alpha Y_t + (1-\alpha)(L_{t-1} + T_{t-1}) \\
\text{추세: } T_t &= \beta(L_t - L_{t-1}) + (1-\beta)T_{t-1} \\
\text{예측: } \hat{Y}_{t+h} &= L_t + hT_t
\end{align}
$$

- 추세가 있는 데이터에 적합

#### 4.3.3 삼중 지수평활법 (Triple Exponential Smoothing, Holt-Winters Method)

$$
\begin{align}
\text{수준: } L_t &= \alpha Y_t + (1-\alpha)(L_{t-1} + T_{t-1}) \\
\text{추세: } T_t &= \beta(L_t - L_{t-1}) + (1-\beta)T_{t-1} \\
\text{계절성: } S_t &= \gamma Y_t + (1-\gamma)S_{t-s}
\end{align}
$$

- 추세와 계절성이 모두 있는 데이터에 적합

### 4.4 딥러닝 기반 시계열 분석

#### 4.4.1 LSTM (Long Short-Term Memory)

장기 의존성(Long-term Dependency)을 학습하는 순환 신경망(RNN)의 변형

$$
\begin{align}
f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \\
\tilde{C}_t &= \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) \\
C_t &= f_t \cdot C_{t-1} + i_t \cdot \tilde{C}_t \\
o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \cdot \tanh(C_t)
\end{align}
$$

**특징**: 그래디언트 소실 문제 해결, 장기 기억 보존

#### 4.4.2 GRU (Gated Recurrent Unit)

LSTM의 단순화된 버전으로, 더 적은 파라미터로 유사한 성능

$$
\begin{align}
z_t &= \sigma(W_z \cdot [h_{t-1}, x_t]) \\
r_t &= \sigma(W_r \cdot [h_{t-1}, x_t]) \\
\tilde{h}_t &= \tanh(W \cdot [r_t \cdot h_{t-1}, x_t]) \\
h_t &= (1-z_t) \cdot h_{t-1} + z_t \cdot \tilde{h}_t
\end{align}
$$

### 4.5 Transformer 기반 모델 (Time Series Transformer)

셀프 어텐션(Self-Attention) 메커니즘을 활용하여 시계열 예측

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

**특징**: 병렬 처리 가능, 장단기 의존성 동시 학습, 긴 시계열에 적합

## 5. 장단점

| 방법 | 장점 | 단점 |
|------|------|------|
| **ARIMA** | 통계적 해석 용이, 이론적 토대 확실, 단변량 예측에 강함 | 정상성 가정 필요, 계절성 처리 복잡, 비선형 패턴 모델링 어려움 |
| **지수평활법** | 구현 간단, 계산 효율, 실시간 예측에 적합 | 파라미터 설정 민감, 복잡한 패턴 모델링 제한 |
| **LSTM/GRU** | 비선형 패턴 학습 가능, 장기 의존성 처리 우수, 다변량 데이터 적용 가능 | 계산 비용 높음, 과적합(Overfitting) 위험, 하이퍼파라미터 튜닝 복잡 |
| **Transformer** | 병렬 처리 가능, 긴 시계열 처리, 멀티헤드 어텐션으로 다양한 패턴 학습 | 메모리 사용량 높음, 대규모 데이터 필요, 긴 학습 시간 |

## 6. 다른 기법과 비교

### 6.1 시계열 분석 vs 회귀 분석

| 비교 항목 | 시계열 분석 | 회귀 분석 |
|-----------|-------------|-----------|
| **데이터 구조** | 시간 순서, 의존성 고려 | 독립 표본 가정 |
| **예측 방향** | 과거 데이터 기반 미래 예측 | 특성 변수 기반 목표 변수 예측 |
| **주요 가정** | 정상성, 시간적 의존성 | 선형성, 독립성, 등분산성 |
| **주요 기법** | ARIMA, 지수평활법, LSTM | 선형 회귀, 릿지, 라쏘, 랜덤 포레스트 |
| **적용 분야** | 주가 예측, 수요 예측, 트래픽 예측 | 가격 예측, 매출 분석, 위험 점수 예측 |

### 6.2 시계열 분석 방법 비교

| 방법 | 데이터 요구사항 | 계산 복잡도 | 해석 용이성 | 적합 상황 |
|------|----------------|------------|-----------|-----------|
| **ARIMA** | 정상 시계열, 충분한 과거 데이터 | 낮음~중간 | 높음 | 단변량, 선형 패턴 |
| **SARIMA** | 계절성이 있는 시계열 | 중간 | 높음 | 계절성 명확한 데이터 |
| **지수평활법** | 추세/계절성 패턴 | 낮음 | 높음 | 단순 패턴, 실시간 예측 |
| **LSTM** | 대규모 데이터, 비선형 패턴 | 높음 | 낮음 | 복잡한 비선형 패턴, 다변량 |
| **Transformer** | 대규모 데이터, 긴 시계열 | 매우 높음 | 낮음 | 매우 긴 시계열, 병렬 처리 필요 |

### 6.3 정상성 검정 방법

| 검정 방법 | 귀무가설 ($H_0$) | 결과 해석 | 사용 라이브러리 |
|-----------|-----------------|-----------|---------------|
| **ADF 검정 (Augmented Dickey-Fuller Test)** | 단위근이 존재 (비정상) | $p < 0.05$이면 정상성 | statsmodels.tsa.stattools |
| **KPSS 검정 (Kwiatkowski-Phillips-Schmidt-Shin)** | 데이터가 정상 | $p < 0.05$이면 비정상성 | statsmodels.tsa.stattools |
| **PP 검정 (Phillips-Perron Test)** | 단위근이 존재 (비정상) | $p < 0.05$이면 정상성 | statsmodels.tsa.stattools |

### 6.4 모델 성능 평가 지표

| 지표 | 공식 | 범위 | 해석 |
|------|------|------|------|
| **MAE (Mean Absolute Error)** | $\frac{1}{n}\sum|y_i - \hat{y}_i|$ | $[0, \infty)$ | 낮을수록 좋음, 해석 용이 |
| **MSE (Mean Squared Error)** | $\frac{1}{n}\sum(y_i - \hat{y}_i)^2$ | $[0, \infty)$ | 이상치에 민감 |
| **RMSE (Root Mean Squared Error)** | $\sqrt{MSE}$ | $[0, \infty)$ | 원래 단위와 동일 |
| **MAPE (Mean Absolute Percentage Error)** | $\frac{100\%}{n}\sum\left|\frac{y_i - \hat{y}_i}{y_i}\right|$ | $[0, \infty)$ | 백분율 기반, 단위 무관 |
| **SMAPE (Symmetric MAPE)** | $\frac{200\%}{n}\sum\frac{|y_i - \hat{y}_i|}{|y_i| + |\hat{y}_i|}$ | $[0, 100\%]$ | 대칭적, 0에 가까울수록 좋음 |

## 7. 기술사적 판단 (Engineering Judgment)

### 7.1 모델 선정 기준

| 상황 | 추천 모델 | 이유 |
|------|----------|------|
| **단변량, 선형 패턴, 데이터 적음** | ARIMA | 통계적 해석 용이, 계산 효율 |
| **계절성 명확, 정기적 패턴** | SARIMA | 계절성 효과적 모델링 |
| **실시간 예측, 단순 추세** | 지수평활법 | 계산 빠름, 최근 데이터 반영 |
| **다변량, 비선형 패턴, 대규모 데이터** | LSTM/GRU | 복잡한 패턴 학습, 장기 의존성 처리 |
| **매우 긴 시계열, 병렬 처리 필요** | Transformer | 긴 시계열 처리, GPU 가속 |
| **해석 가능성 중요** | ARIMA, 지수평활법 | 통계적 해석 용이 |
| **예측 정확도 중요** | LSTM, Transformer, 딥러닝 기반 | 복잡한 패턴 학습 능력 |

### 7.2 데이터 전처리 고려사항

#### 7.2.1 결측치 처리

| 방법 | 설명 | 적용 상황 |
|------|------|-----------|
| **삭제 (Deletion)** | 결측치가 있는 시점 삭제 | 결측치가 적고 무작위일 때 |
| **전방 채우기 (Forward Fill)** | 이전 값으로 채움 | 연속성이 중요할 때 |
| **후방 채우기 (Backward Fill)** | 이후 값으로 채움 | 역추정 가능할 때 |
| **선형 보간 (Linear Interpolation)** | 두 점 사이 선형으로 채움 | 결측 구간이 짧을 때 |
| **보간법 (Spline/Polynomial)** | 곡선 보간으로 채움 | 부드러운 패턴 필요할 때 |

#### 7.2.2 이상치 탐지 및 처리

| 방법 | 설명 | 임계값 |
|------|------|--------|
| **Z-Score** | 표준화된 잔차 기반 | $\left|\frac{x - \mu}{\sigma}\right| > 3$ |
| **IQR (Interquartile Range)** | 사분위 범위 기반 | $x < Q_1 - 1.5 \times IQR$ 또는 $x > Q_3 + 1.5 \times IQR$ |
| **MA (Moving Average)** | 이동평균에서 큰 편차 | $|x_t - \text{MA}(x)_t| > k \times \text{std}$ |
| **Isolation Forest** | 고립 기반 이상치 탐지 | 딥러닝 기반, 비선형 데이터 |

#### 7.2.3 정상성 변환

| 기법 | 설명 | 적용 예시 |
|------|------|-----------|
| **차분 (Differencing)** | 1차: $Y_t - Y_{t-1}$, 2차: $(Y_t - Y_{t-1}) - (Y_{t-1} - Y_{t-2})$ | 추세 제거 |
| **로그 변환 (Log Transformation)** | $\ln(Y_t)$ | 분산 안정화, 비대칭성 완화 |
| **Box-Cox 변환** | $(Y_t^\lambda - 1)/\lambda$ ($\lambda \neq 0$) | 정규성 향상 |
| **제곱근 변환 (Square Root Transformation)** | $\sqrt{Y_t}$ | 분산 감소, 정규성 향상 |

### 7.3 하이퍼파라미터 튜닝

#### 7.3.1 ARIMA 파라미터 결정

| 파라미터 | 결정 방법 | 시각적 도구 |
|----------|-----------|-----------|
| $p$ (AR 차수) | PACF(Partial ACF) | PACF 그래프, AIC/BIC 최소화 |
| $q$ (MA 차수) | ACF(Autocorrelation Function) | ACF 그래프, AIC/BIC 최소화 |
| $d$ (차분 차수) | 정상성 검정 (ADF, KPSS) | ADF 검정 p-value, 차분 후 그래프 |
| $(P, D, Q)$ | 계절성 ACF/PACF 분석 | 계절성 주기 $s$ 기반 |

#### 7.3.2 딥러닝 파라미터 튜닝

| 파라미터 | 범위 | 영향 |
|----------|------|------|
| **Learning Rate** | $10^{-4} \sim 10^{-3}$ | 수렴 속도, 안정성 |
| **Batch Size** | 16~128 | 메모리 사용, 수렴 안정성 |
| **Hidden Units** | 32~512 | 표현력, 과적합 위험 |
| **Dropout Rate** | 0.1~0.5 | 과적합 방지 |
| **Sequence Length** | 24~168 (1주~1개월) | 장단기 의존성 학습 |

### 7.4 실무 적용 시 주의사항

#### 7.4.1 교차 검증 (Cross-Validation)

일반적인 K-Fold 교차 검증은 시계열 데이터에 부적합

| 방법 | 설명 | 구현 |
|------|------|------|
| **Time Series Split** | 시간 순서 유지하며 데이터 분할 | sklearn.model_selection.TimeSeriesSplit |
| **Rolling Forecast** | 이동 윈도우로 예측 및 평가 | 직접 구현 필요 |
| **Expanding Window** | 훈련 데이터를 점진적 확장 | 직접 구현 필요 |

#### 7.4.2 데이터 누수 (Data Leakage) 방지

- 미래 정보를 훈련 데이터에 포함하지 않음
- 특성 엔지니어링 시 시간적 순서 준수
- 테스트 데이터는 예측 시점 이후의 데이터로 구성

#### 7.4.3 모델 해석 가능성

| 모델 | 해석 가능성 | 기법 |
|------|-----------|------|
| **ARIMA** | 높음 | 계수 해석, 통계적 검정 |
| **지수평활법** | 높음 | 수준, 추세, 계절성 파라미터 |
| **LSTM** | 낮음 | SHAP, LIME, Attention 가중치 |
| **Transformer** | 낮음 | Attention 맵 시각화, SHAP |

### 7.5 도메인별 적용 사례

| 도메인 | 활용 사례 | 추천 모델 | 특별 고려사항 |
|--------|-----------|----------|--------------|
| **금융/주식** | 주가 예측, 포트폴리오 최적화 | LSTM, Transformer, ARIMA | 높은 변동성, 뉴스/감성 분석 결합 |
| **에너지/전력** | 전력 수요 예측, 발전량 최적화 | LSTM, SARIMA, Prophet | 계절성 명확, 기상 데이터 결합 |
| **제조/공급망** | 수요 예측, 재고 관리 | ARIMA, SARIMA, 지수평활법 | 프로모션 이벤트, 계절성 고려 |
| **네트워크/IT** | 트래픽 예측, 장애 예측 | LSTM, GRU, Prophet | 다변량(서버, 앱, 사용자) 분석 |
| **의료/건강** | 환자 상태 예측, 질병 발생 예측 | LSTM, Transformer | 개인별 패턴, 라이프로그 결합 |
| **소매/E-commerce** | 판매 예측, 재고 최적화 | SARIMA, Prophet, LightGBM | 계절성, 이벤트, 경쟁사 데이터 |

## 8. 미래 전망

| 기술 | 설명 | 기대 효과 |
|------|------|-----------|
| **사전 학습된 시계열 모델 (Pre-trained Time Series Models)** | NLP에서의 BERT처럼 시계열 전용 사전 학습 모델 | 적은 데이터로도 높은 성능, 도메인 간 전이 학습 가능 |
| **멀티모달 시계열 분석 (Multimodal Time Series)** | 텍스트, 이미지, 오디오 등 시계열과 결합 | 뉴스 텍스트 + 주가, 이미지 + 매출 등 융합 예측 |
| **자동화된 시계열 분석 (AutoML for Time Series)** | Facebook Prophet, AutoARIMA, AutoTS 등 자동 모델 선정 | 시간 절약, 비전문가도 활용 가능 |
| **온라인 학습 (Online Learning)** | 실시간 데이터 스트림으로 모델 지속 업데이트 | IoT, 실시간 모니터링 시스템 적용 |
| **분산 학습 (Distributed Learning)** | 대규모 시계열 데이터 병렬 처리 | 대규모 클러스터, GPU 가속 처리 |
| **설명 가능한 AI (Explainable AI, XAI) for Time Series** | 시계열 예측 근거 시각화 | 의사결정 지원, 신뢰성 향상 |
| **예지 보전 (Predictive Maintenance)** | 장비 고장 예측, 유지보수 스케줄링 | 제조, 인프라 비용 절감 |

---

## 부록: 어린이를 위한 설명

### 비유로 이해하는 시계열 🕰️

#### 1. 시계열은 "날씨 일기장" 🌤️

> 날씨를 매일매일 적는 일기장을 상상해 봐요!
>
> - **1월 1일**: 5도, 맑음
> - **1월 2일**: 6도, 흐림
> - **1월 3일**: 7도, 비
> - ...
> - **12월 31일**: 2도, 눈
>
> **이걸 시간 순서대로 정리한 게 바로 시계열이야!**
>
> "어제 날씨를 보고 오늘 날씨를 예측하는 것" = 시계열 분석

#### 2. 추세(Trend)는 "키 자라기" 📏

> 친구 키를 1년 동안 재보면:
>
> - 1월: 140cm
> - 2월: 141cm
> - 3월: 142cm
> - ...
> - 12월: 151cm
>
> **계속 커지는 걸 볼 수 있어요!** 이게 바로 **추세**예요.
>
> "점점 커지는 트렌드" → 증가 추세
> "점점 작아지는 트렌드" → 감소 추세

#### 3. 계절성(Seasonality)은 "빙과게 팔리는 계절" 🍦

> 아이스크림 가게 매출을 봐요:
>
> - **여름(6~8월)**: 아이스크림 많이 팔아요! 🥵
> - **겨울(12~2월)**: 아이스크림 별로 안 팔려요! ❄️
>
> **매년 같은 패턴이 반복돼요!** 이게 바로 **계절성**이에요.
>
> - 명절마다 선물이 많이 팔려요 🎁
> - 방학마다 학용품이 많이 팔려요 📚
> - 연말에 여행 예약이 많이 해요 ✈️

#### 4. 순환성(Cyclicity)은 "경기의 호황과 불황" 📈📉

> 친구들의 장난감 인기도를 봐요:
>
> - 처음엔 "자동차 장난감"이 인기 🚗
> - 나중엔 "로봇 장난감"이 인기 🤖
> - 또 나중엔 다시 "자동차"가 인기 🚗
>
> **고정된 기간 없이 오르내려요!** 이게 바로 **순환성**이에요.
>
> 경기도 좋았다 나빴다 반복돼요. (몇 년 단위)

#### 5. 불규칙성(Irregularity)은 "뜬금없는 일" 🎲

> 매일 공부하는 시간을 적어봐요:
>
> - 월요일: 2시간
> - 화요일: 2시간
> - 수요일: **2시간이 아니라, 갑자기 친구가 와서 30분만 공부!**
> - 목요일: 2시간
>
> **갑자기 특이한 일이 일어날 수 있어요!** 이게 바로 **불규칙성**이에요.
>
> - 비가 갑자기 와서 축구 못 함 ⚽
> - TV가 갑자기 고장 남 📺
> - 뜬금없이 떨어지는 별 ⭐

#### 6. ARIMA는 "어제/그제 기억해서 예측하기" 🧠

> ARIMA는 세 가지를 고려해요:
>
> **1. AR (자기회귀, Autoregressive)**
> - "어제 공부 시간이 길면, 오늘도 길겠지?"
> - **과거의 나를 봐서 오늘 예측해요**
>
> **2. MA (이동평균, Moving Average)**
> - "어제 예측이 틀렸으면, 오늘은 그걸 반영하자!"
> - **실수를 기억해서 예측해요**
>
> **3. I (차분, Integrated)**
> - "계속 커지면, 증가분만 따로 봐!"
> - **추세를 없애고 예측해요**

#### 7. LSTM은 "장기 기억 있는 친구" 🧠

> 일반 RNN은 기억이 짧아서 옛날 걸 금방 잊어버려요. 😢
>
> **LSTM은 기억 선택적으로 보관해요!**
>
> - 중요한 건 **오래 기억** 🔒
> - 중요하지 않은 건 **빨리 잊어버림** 🗑️
>
> **장기 기억을 잘해서 긴 시계열도 예측할 수 있어요!**

### 요약 🎯

| 개념 | 비유 | 기억법 |
|------|------|--------|
| **시계열** | 날씨 일기장 | 시간 순서대로 적은 데이터 |
| **추세** | 키 자라기 | 계속 커지거나 작아지는 패턴 |
| **계절성** | 아이스크림 팔리는 계절 | 매년 같은 시기에 반복 |
| **순환성** | 장난감 인기도 오르내림 | 기간 없이 오르내림 |
| **불규칙성** | 뜬금없는 일 | 예측할 수 없는 엉뚱한 일 |
| **ARIMA** | 어제/그제 기억해서 예측 | 과거를 보고 미래 예측 |
| **LSTM** | 장기 기억 있는 친구 | 오래된 것도 기억하는 똑똑이 |

**💡 한 줄 요약**: "과거의 패턴을 보고 미래를 예측하는 시간 여행 능력!" ⏰✨
