# 군집 알고리즘 (Clustering Algorithm)

## 1. 개념

군집 알고리즘(Clustering Algorithm)은 비지도 학습(Unsupervised Learning)의 일종으로, 유사한 데이터 포인트를 같은 그룹(클러스터)으로 묶는 기법입니다. 라벨링되지 않은 데이터를 유사성에 기반하여 자동으로 분류하며, 데이터의 내부 구조를 발견하고 패턴을 식별하는 데 사용됩니다.

## 2. 등장 배경

- **데이터 마이닝 (Data Mining)**: 대규모 데이터에서 숨겨진 패턴 발견 필요성 증대
- **비지도 학습 (Unsupervised Learning)**: 라벨링 비용 절감 및 자동 분류 요구
- **빅데이터 시대 (Big Data Era)**: 정형/비정형 데이터의 그룹핑 및 요약 필요
- **고객 세분화 (Customer Segmentation)**: 마케팅, 추천 시스템 등에서 타겟팅 효율화

## 3. 구성 요소

| 유형 | 대표 알고리즘 | 특징 | 데이터 형태 | 적용 분야 |
|------|--------------|------|------------|-----------|
| **분할형 (Partitioning)** | K-Means, K-Medoids | 중심점 기반, 볼록 형태 클러스터 | 수치형 벡터 | 고객 세분화, 이미지 압축 |
| **계층형 (Hierarchical)** | Agglomerative, Divisive | 덴드로그램(Dendrogram), 다층 구조 | 다양한 형태 | 유전자 분석, 문서 클러스터링 |
| **밀도 기반 (Density-based)** | DBSCAN, OPTICS | 밀도 기반, 비볼록 형태 지원 | 공간 데이터 | 이상치 탐지, 지리 데이터 |
| **분포 기반 (Distribution-based)** | Gaussian Mixture Model(GMM) | 확률 분포 기반 | 수치형 데이터 | 통계적 분류, 패턴 인식 |
| **그래프 기반 (Graph-based)** | Spectral Clustering | 그래프 컷 기반 | 관계형 데이터 | 소셜 네트워크, 이미지 분할 |

## 4. 핵심 원리

### 4.1 K-Means (K-평균 클러스터링)

$$
\text{목적 함수: } J = \sum_{i=1}^{K} \sum_{x \in C_i} ||x - \mu_i||^2
$$

**알고리즘 절차**:
1. 초기 K개의 중심점(Centroid) 무작위 선택
2. 각 데이터 포인트를 가장 가까운 중심점에 할당
3. 각 클러스터의 평균으로 중심점 갱신
4. 수렴할 때까지 2-3단계 반복

**특징**: 구현 간단, 수렴 속도 빠름, K값 사전 지정 필요

### 4.2 계층적 군집 (Hierarchical Clustering)

| 방식 | 설명 | 복잡도 |
|------|------|--------|
| **Agglomerative (Bottom-up)** | 각 데이터 포인트를 개별 클러스터로 시작하여 가장 유사한 클러스터를 순차적 병합 | $O(N^3)$ (Naive) |
| **Divisive (Top-down)** | 전체를 하나의 클러스터로 시작하여 분할 | $O(2^N)$ |

**거리 측정 방법**:
- Single Linkage: 최소 거리
- Complete Linkage: 최대 거리
- Average Linkage: 평균 거리
- Ward's Method: 분산 최소화

### 4.3 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

**핵심 파라미터**:
- $\epsilon$ (Epsilon): 반경
- MinPts: 최소 포인트 수

**포인트 분류**:
- Core Point: $\epsilon$ 반경 내에 MinPts 이상의 포인트
- Border Point: $\epsilon$ 반경 내에 Core Point 존재
- Noise Point: Core Point도 Border Point도 아님

**특징**: 클러스터 개수 자동 결정, 이상치 탐지 우수, 밀도 다른 클러스터 식별 가능

### 4.4 Gaussian Mixture Model (GMM)

$$
P(x) = \sum_{k=1}^{K} \pi_k \mathcal{N}(x | \mu_k, \Sigma_k)
$$

**추정 방법**: EM (Expectation-Maximization) 알고리즘

**특징**: 유연한 클러스터 형태, 확률적 할당, K-Means보다 일반화

## 5. 장단점

| 알고리즘 | 장점 | 단점 |
|---------|------|------|
| **K-Means** | 구현 간단, 계산 효율 높음, 대규모 데이터 적용 가능 | K값 사전 지정, 초기값 민감, 비볼록 클러스터 불가, 이상치에 취약 |
| **계층적 군집** | 클러스터 계층 구조 시각화 가능, K값 불필요 | 계산 복잡도 높음, 일회성 분할 불가 |
| **DBSCAN** | 클러스터 수 자동 결정, 비볼 convex 형태 지원, 이상치 탐지 우수 | $\epsilon$, MinPts 설정 어려움, 밀도 다른 클러스터 식별 어려움 |
| **GMM** | 유연한 클러스터 형태, 소프트 할당(확률적) | 계산 복잡도 높음, 정규분포 가정 필요 |

## 6. 다른 기법과 비교

| 비교 항목 | 군집 (Clustering) | 분류 (Classification) |
|-----------|------------------|----------------------|
| **학습 방식** | 비지도 (Unsupervised) | 지도 (Supervised) |
| **라벨 여부** | 없음 | 있음 |
| **목적** | 데이터 그룹핑, 패턴 발견 | 새로운 데이터 예측 |
| **평가 방식** | 실루엣 계수, Dunn 지수, Davies-Bouldin 지수 | 정확도, 정밀도, 재현율, F1-score |

### 군집 성능 평가 지표

| 지표 | 설명 | 범위 |
|------|------|------|
| **실루엣 계수 (Silhouette Coefficient)** | 클러스터 내 응집도와 분리도 측정 | [-1, 1] (높을수록 좋음) |
| **Dunn 지수** | 최소 클러스터 간 거리 / 최대 클러스터 직경 | [0, ∞] (높을수록 좋음) |
| **Davies-Bouldin 지수** | 클러스터 내 분산 / 클러스터 간 거리 | [0, ∞] (낮을수록 좋음) |

## 7. 기술사적 판단 (Engineering Judgment)

### 7.1 알고리즘 선정 기준

| 상황 | 추천 알고리즘 | 이유 |
|------|--------------|------|
| **데이터 양이 많고 형태가 단순** | K-Means | 계산 효율성 우수, 구현 용이 |
| **클러스터 수 미상** | 계층적 군집, DBSCAN | K값 자동 결정 가능 |
| **비볼convex 형태 클러스터** | DBSCAN, Spectral Clustering | 밀도/그래프 기반으로 유연한 형태 지원 |
| **이상치 존재** | DBSCAN, K-Medoids | 이상치 영향 최소화 |
| **확률적 할당 필요** | GMM | 소프트 클러스터링 제공 |

### 7.2 데이터 전처리 고려사항

1. **정규화 (Normalization)**: K-Means, GMM 등 거리 기반 알고리즘은 필수
   - Min-Max Scaling, Z-score Standardization 활용

2. **차원 축소 (Dimensionality Reduction)**:
   - PCA (Principal Component Analysis), t-SNE, UMAP
   - 차원의 저주(Curse of Dimensionality) 방지

3. **결측치 처리**: 평균/중앙값 대체 또는 삭제

### 7.3 하이퍼파라미터 튜닝

- **K-Means**: K값 선정 (Elbow Method, Silhouette Analysis)
- **DBSCAN**: $\epsilon$ (K-distance 그래프), MinPts
- **계층적 군집**: 거리 측정 방법 (Linkage)

### 7.4 실무 적용 시 주의사항

- **스케일 민감성**: 데이터 단위 통일 필수
- **초기값 민감성**: K-Means, GMM은 다중 초기화(K-Means++) 권장
- **평가 지표 활용**: 도메인 지식과 결합하여 결과 검증

### 7.5 도메인별 적용 사례

| 도메인 | 활용 사례 | 추천 알고리즘 |
|--------|-----------|--------------|
| **마케팅** | 고객 세분화, RFM 분석 | K-Means, 계층적 군집 |
| **이상치 탐지** | 사기 탐지, 시스템 장애 감지 | DBSCAN, Isolation Forest |
| **이미지 처리** | 색상 양자화, 객체 분할 | K-Means, Spectral Clustering |
| **자연어 처리** | 문서 클러스터링, 토픽 모델링 | K-Means, LDA (Latent Dirichlet Allocation) |
| **생물정보학** | 유전자 발현 패턴 분석 | 계층적 군집, GMM |

## 8. 미래 전망

| 기술 | 설명 | 기대 효과 |
|------|------|-----------|
| **딥러닝 기반 군집** (Deep Clustering) | Autoencoder, Deep Embedded Clustering(DEC) 등 신경망과 결합 | 고차원 데이터 표현 학습, 복잡한 패턴 발견 |
| **대규모 병렬 처리** | GPU, 분산 컴퓨팅 활용 | 실시간 대규모 데이터 군집화 가능 |
| **멀티뷰 군집** (Multi-view Clustering) | 다양한 관점의 데이터 동시 활용 | 정보 융합을 통한 정확도 향상 |
| **동적 군집** (Dynamic/Streaming Clustering) | 실시간 데이터 스트림 처리 | IoT, 실시간 모니터링 시스템 적용 |
| **자가 지도 학습** (Self-supervised Learning) | 라벨 없는 데이터로부터 표현 학습 | 대규모 미라벨링 데이터 활용 |

---

## 부록: 어린이를 위한 설명

### 비유로 이해하는 군집 알고리즘 🎨

#### 1. K-Means는 "팀 나누기 게임" 🏃‍♂️

> 운동장에 친구들이 둥글게 서 있어요!
>
> - **1단계**: 4명의 팀장(중심점)이 운동장 여기저기에 서요
> - **2단계**: 각 친구는 **"제일 가까운 팀장이 누구?"** 하고 팀을 정해요
> - **3단계**: 팀장은 **"우리 팀 사람들의 중간 어디가 가장 편할까?"** 하고 자리를 이동해요
> - **4단계**: 친구들이 다시 가까운 팀장 찾기...
>
> **팀장이 더 이상 움직이지 않을 때까지 반복! 그게 K-Means예요!**

#### 2. 계층적 군집은 "가계도 만들기" 🌳

> 동물들이 친척 관계를 정리해 봐요!
>
> - **처음**: 강아지, 고양이, 호랑이, 사자, 돌고래, 고래가 각자 따로 놀아요
> - **1단계**: 비슷한 동물끼리 짝꿍을 지어요 (강아지+고양이, 호랑이+사자, 돌고래+고래)
> - **2단계**: 다시 큰 그룹으로 합쳐요 ((강아지+고양이) + (호랑이+사자))
> - **3단계**: 최종적으로 **고양이과**와 **고래류**로 나눠요
>
> **나무처럼 촘촘하게 그려서 보여주면 덴드로그램(가계도)이 돼요!**

#### 3. DBSCAN은 "인기 있는 친구 찾기" 👥

> 교실에 친구들이 흩어져 있어요!
>
> - **인기 친구 (Core Point)**: 반경 2미터 안에 친구가 5명 이상 있는 친구
> - **친구의 친구 (Border Point)**: 인기 친구 옆에 있는 친구
> - **외톨이 (Noise Point)**: 혼자 멀리 떨어져 있는 친구 😢
>
> **인기 친구와 그 친구들을 한 팀으로 묶어요! 팀 수는 자연스럽게 정해져요.**

#### 4. GMM은 "확률로 팀 정하기" 🎲

> 친구들이 학교에 오는 길을 예측해 봐요!
>
> - 친구 A가 학교에 올 확률: **80%** → 1반
> - 친구 A가 학교에 올 확률: **20%** → 2반
>
> K-Means는 "무조건 1반!" 이라고 하지만,
> GMM은 "**80%는 1반인 것 같고, 20%는 2반인 것 같아**"라고 말해요!
>
> **확률로 생각해서 더 유연해요!**

### 요약 🎯

| 친구 | 무슨 게임인지? | 언제 쓸까요? |
|------|--------------|-------------|
| K-Means | 팀장 따라 팀 나누기 | 친구들 비슷한 그룹으로 묶을 때 |
| 계층적 군집 | 가계도 만들기 | 작은 그룹부터 큰 그룹으로 단계적으로 나눌 때 |
| DBSCAN | 인기 친구 찾기 | 덩어리 있는 곳 찾고 외톨이 찾을 때 |
| GMM | 확률로 팀 정하기 | "이 그룹일 확률"이 얼마나 되는지 알고 싶을 때 |

**💡 한 줄 요약**: "비슷한 친구끼리 자연스럽게 모여주는 마법의 정리술!" ✨
